{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXU1JBjZ6BNcd7qkQjvXLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamshi-0408/Nlp/blob/main/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"couldn‚Äôt\"\n",
        "print(len(text)) # print length of text\n",
        "print('----------')\n",
        "print(len(text.encode(\"utf-8\"))) # print length of text\n",
        "print('----------')\n",
        "print(text.encode(\"utf-8\")) # print the raw bytes\n",
        "print('----------')\n",
        "print(list(map(int,text.encode(\"utf-8\")))) # print the raw bytes\n",
        "print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHcZtwsbFmKZ",
        "outputId": "7288502f-8886-45b5-bb11-796ff2ed1ce7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "----------\n",
            "10\n",
            "----------\n",
            "b'couldn\\xe2\\x80\\x99t'\n",
            "----------\n",
            "[99, 111, 117, 108, 100, 110, 226, 128, 153, 116]\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = list(map(int,text.encode(\"utf-8\")))\n",
        "print(tokens)\n",
        "print('----------')\n",
        "print(len(tokens)) # print length of tokens\n",
        "print('----------')\n",
        "print(bytes(tokens)) # print length of raw bytes\n",
        "print('----------')\n",
        "print(bytes(tokens).decode(\"utf-8\")) # print the raw bytes\n",
        "print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O1Q7w6OGihu",
        "outputId": "d813683b-3c38-43ad-dd1f-84ca393fbd27"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[99, 111, 117, 108, 100, 110, 226, 128, 153, 116]\n",
            "----------\n",
            "10\n",
            "----------\n",
            "b'couldn\\xe2\\x80\\x99t'\n",
            "----------\n",
            "couldn‚Äôt\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ptUbdN_c9_U_"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Once upon a time, in a lush forest, a speedy hare bragged about being the fastest.\n",
        "A slow tortoise challenged him to a race.\n",
        "The hare laughed but accepted.On race day, the hare dashed ahead and, confident of victory, decided to take a nap.\n",
        "Meanwhile, the tortoise kept moving steadily.\n",
        "When the hare woke up, he sprinted toward the finish line, but to his shock, the tortoise was almost there! Despite his speed, the hare couldn‚Äôt catch up in time.\n",
        "The tortoise crossed the finish line first.The hare learned that 'slow and steady wins the race!' üê¢üèÅ\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "  assert isinstance(text, str), \"Expected a string\"\n",
        "  raw_bytes = text.encode(\"utf-8\") # raw bytes\n",
        "  tokens = list(map(int,raw_bytes)) # convert to list of integers in range 0-255\n",
        "  return tokens\n",
        "\n",
        "tokens = tokenizer(text)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0wPOU6A-VDG",
        "outputId": "5002626f-1c43-4f4a-d0c3-8f3aebdeb18d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[79, 110, 99, 101, 32, 117, 112, 111, 110, 32, 97, 32, 116, 105, 109, 101, 44, 32, 105, 110, 32, 97, 32, 108, 117, 115, 104, 32, 102, 111, 114, 101, 115, 116, 44, 32, 97, 32, 115, 112, 101, 101, 100, 121, 32, 104, 97, 114, 101, 32, 98, 114, 97, 103, 103, 101, 100, 32, 97, 98, 111, 117, 116, 32, 98, 101, 105, 110, 103, 32, 116, 104, 101, 32, 102, 97, 115, 116, 101, 115, 116, 46, 10, 65, 32, 115, 108, 111, 119, 32, 116, 111, 114, 116, 111, 105, 115, 101, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 100, 32, 104, 105, 109, 32, 116, 111, 32, 97, 32, 114, 97, 99, 101, 46, 10, 84, 104, 101, 32, 104, 97, 114, 101, 32, 108, 97, 117, 103, 104, 101, 100, 32, 98, 117, 116, 32, 97, 99, 99, 101, 112, 116, 101, 100, 46, 79, 110, 32, 114, 97, 99, 101, 32, 100, 97, 121, 44, 32, 116, 104, 101, 32, 104, 97, 114, 101, 32, 100, 97, 115, 104, 101, 100, 32, 97, 104, 101, 97, 100, 32, 97, 110, 100, 44, 32, 99, 111, 110, 102, 105, 100, 101, 110, 116, 32, 111, 102, 32, 118, 105, 99, 116, 111, 114, 121, 44, 32, 100, 101, 99, 105, 100, 101, 100, 32, 116, 111, 32, 116, 97, 107, 101, 32, 97, 32, 110, 97, 112, 46, 10, 77, 101, 97, 110, 119, 104, 105, 108, 101, 44, 32, 116, 104, 101, 32, 116, 111, 114, 116, 111, 105, 115, 101, 32, 107, 101, 112, 116, 32, 109, 111, 118, 105, 110, 103, 32, 115, 116, 101, 97, 100, 105, 108, 121, 46, 10, 87, 104, 101, 110, 32, 116, 104, 101, 32, 104, 97, 114, 101, 32, 119, 111, 107, 101, 32, 117, 112, 44, 32, 104, 101, 32, 115, 112, 114, 105, 110, 116, 101, 100, 32, 116, 111, 119, 97, 114, 100, 32, 116, 104, 101, 32, 102, 105, 110, 105, 115, 104, 32, 108, 105, 110, 101, 44, 32, 98, 117, 116, 32, 116, 111, 32, 104, 105, 115, 32, 115, 104, 111, 99, 107, 44, 32, 116, 104, 101, 32, 116, 111, 114, 116, 111, 105, 115, 101, 32, 119, 97, 115, 32, 97, 108, 109, 111, 115, 116, 32, 116, 104, 101, 114, 101, 33, 32, 68, 101, 115, 112, 105, 116, 101, 32, 104, 105, 115, 32, 115, 112, 101, 101, 100, 44, 32, 116, 104, 101, 32, 104, 97, 114, 101, 32, 99, 111, 117, 108, 100, 110, 226, 128, 153, 116, 32, 99, 97, 116, 99, 104, 32, 117, 112, 32, 105, 110, 32, 116, 105, 109, 101, 46, 10, 84, 104, 101, 32, 116, 111, 114, 116, 111, 105, 115, 101, 32, 99, 114, 111, 115, 115, 101, 100, 32, 116, 104, 101, 32, 102, 105, 110, 105, 115, 104, 32, 108, 105, 110, 101, 32, 102, 105, 114, 115, 116, 46, 84, 104, 101, 32, 104, 97, 114, 101, 32, 108, 101, 97, 114, 110, 101, 100, 32, 116, 104, 97, 116, 32, 39, 115, 108, 111, 119, 32, 97, 110, 100, 32, 115, 116, 101, 97, 100, 121, 32, 119, 105, 110, 115, 32, 116, 104, 101, 32, 114, 97, 99, 101, 33, 39, 32, 240, 159, 144, 162, 240, 159, 143, 129]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenizer(tokens):\n",
        "  assert isinstance(tokens, list), \"Expected a list of integers\"\n",
        "  raw_bytes = bytes(tokens)\n",
        "  decoded_string = raw_bytes.decode('utf-8') #Decode the bytes to a string (using UTF-8 encoding)\n",
        "  return decoded_string\n",
        "detokenizer(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0Geimwug_Xn5",
        "outputId": "feed1a0b-205e-47f7-a806-3c29b4b712bd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Once upon a time, in a lush forest, a speedy hare bragged about being the fastest.\\nA slow tortoise challenged him to a race.\\nThe hare laughed but accepted.On race day, the hare dashed ahead and, confident of victory, decided to take a nap.\\nMeanwhile, the tortoise kept moving steadily.\\nWhen the hare woke up, he sprinted toward the finish line, but to his shock, the tortoise was almost there! Despite his speed, the hare couldn‚Äôt catch up in time.\\nThe tortoise crossed the finish line first.The hare learned that 'slow and steady wins the race!' üê¢üèÅ\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}